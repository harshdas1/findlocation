import nltk
from nltk.corpus import stopwords

# Download stopwords (only the first time)
nltk.download('stopwords')

# Define the documents
document1 = "The quick brown fox jumped over the lazy dog"
document2 = "The lazy dog slept in the sun"

# Get stopwords for English
stopWords = stopwords.words('english')

# Step 1: Tokenize and normalize
tokens1 = document1.lower().split()
tokens2 = document2.lower().split()

# Get unique terms across both documents
terms = list(set(tokens1 + tokens2))

# Step 2: Build inverted index and occurrence counts
inverted_index = {}
occ_num_doc1 = {}
occ_num_doc2 = {}

for term in terms:
    if term in stopWords:
        continue  # Skip stopwords

    documents = []

    if term in tokens1:
        documents.append("Document 1")
        occ_num_doc1[term] = tokens1.count(term)

    if term in tokens2:
        documents.append("Document 2")
        occ_num_doc2[term] = tokens2.count(term)

    inverted_index[term] = documents

# Step 3: Print the inverted index
print("=== Inverted Index ===\n")
for term, documents in inverted_index.items():
    print(term, "->", end=" ")
    for doc in documents:
        if doc == "Document 1":
            print(f"{doc} ({occ_num_doc1.get(term, 0)}),", end=" ")
        elif doc == "Document 2":
            print(f"{doc} ({occ_num_doc2.get(term, 0)}),", end=" ")
    print()

print("\nPerformed by 740_Pallavi & 743_Deepak")
